{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Speech_program\\F5-TTS\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Vocos from huggingface charactr/vocos-mel-24khz\n",
      "\n",
      "vocab :  D:\\Speech_program\\F5-TTS\\models\\F5-TTS\\vocab.txt\n",
      "token :  custom\n",
      "model :  D:\\Speech_program\\F5-TTS\\models\\F5-TTS\\model_1250000.safetensors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "from importlib.resources import files\n",
    "\n",
    "import soundfile as sf\n",
    "import tqdm\n",
    "from cached_path import cached_path\n",
    "from hydra.utils import get_class\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from f5_tts.infer.utils_infer import (\n",
    "    load_model,\n",
    "    load_vocoder,\n",
    "    transcribe,\n",
    "    preprocess_ref_audio_text,\n",
    "    infer_process,\n",
    "    remove_silence_for_generated_wav,\n",
    "    save_spectrogram,\n",
    ")\n",
    "from f5_tts.model.utils import seed_everything\n",
    "\n",
    "\n",
    "class F5TTS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=\"F5TTS_v1_Base\",\n",
    "        ckpt_file=\"D:\\Speech_program\\F5-TTS\\models\\F5-TTS\\model_1250000.safetensors\",\n",
    "        vocab_file=\"D:\\\\Speech_program\\\\F5-TTS\\\\models\\\\F5-TTS\\\\vocab.txt\",\n",
    "        ode_method=\"euler\",\n",
    "        use_ema=True,\n",
    "        vocoder_local_path=None,\n",
    "        device=None,\n",
    "        hf_cache_dir=None,\n",
    "    ):\n",
    "        model_cfg = OmegaConf.load(str(files(\"f5_tts\").joinpath(f\"configs/{model}.yaml\")))\n",
    "        model_cls = get_class(f\"f5_tts.model.{model_cfg.model.backbone}\")\n",
    "        model_arc = model_cfg.model.arch\n",
    "\n",
    "        self.mel_spec_type = model_cfg.model.mel_spec.mel_spec_type\n",
    "        self.target_sample_rate = model_cfg.model.mel_spec.target_sample_rate\n",
    "\n",
    "        self.ode_method = ode_method\n",
    "        self.use_ema = use_ema\n",
    "\n",
    "        if device is not None:\n",
    "            self.device = device\n",
    "        else:\n",
    "            import torch\n",
    "\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"xpu\"\n",
    "                if torch.xpu.is_available()\n",
    "                else \"mps\"\n",
    "                if torch.backends.mps.is_available()\n",
    "                else \"cpu\"\n",
    "            )\n",
    "\n",
    "        # Load models\n",
    "        self.vocoder = load_vocoder(\n",
    "            self.mel_spec_type, vocoder_local_path is not None, vocoder_local_path, self.device, hf_cache_dir\n",
    "        )\n",
    "\n",
    "        repo_name, ckpt_step, ckpt_type = \"F5-TTS\", 1250000, \"safetensors\"\n",
    "\n",
    "        # override for previous models\n",
    "        if model == \"F5TTS_Base\":\n",
    "            if self.mel_spec_type == \"vocos\":\n",
    "                ckpt_step = 1200000\n",
    "            elif self.mel_spec_type == \"bigvgan\":\n",
    "                model = \"F5TTS_Base_bigvgan\"\n",
    "                ckpt_type = \"pt\"\n",
    "        elif model == \"E2TTS_Base\":\n",
    "            repo_name = \"E2-TTS\"\n",
    "            ckpt_step = 1200000\n",
    "\n",
    "        if not ckpt_file:\n",
    "            ckpt_file = str(\n",
    "                cached_path(f\"hf://SWivid/{repo_name}/{model}/model_{ckpt_step}.{ckpt_type}\", cache_dir=hf_cache_dir)\n",
    "            )\n",
    "        self.ema_model = load_model(\n",
    "            model_cls, model_arc, ckpt_file, self.mel_spec_type, vocab_file, self.ode_method, self.use_ema, self.device\n",
    "        )\n",
    "\n",
    "    def transcribe(self, ref_audio, language=None):\n",
    "        return transcribe(ref_audio, language)\n",
    "\n",
    "    def export_wav(self, wav, file_wave, remove_silence=False):\n",
    "        sf.write(file_wave, wav, self.target_sample_rate)\n",
    "\n",
    "        if remove_silence:\n",
    "            remove_silence_for_generated_wav(file_wave)\n",
    "\n",
    "    def export_spectrogram(self, spec, file_spec):\n",
    "        save_spectrogram(spec, file_spec)\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        ref_file,\n",
    "        ref_text,\n",
    "        gen_text,\n",
    "        show_info=print,\n",
    "        progress=tqdm,\n",
    "        target_rms=0.1,\n",
    "        cross_fade_duration=0.15,\n",
    "        sway_sampling_coef=-1,\n",
    "        cfg_strength=2,\n",
    "        nfe_step=32,\n",
    "        speed=1.0,\n",
    "        fix_duration=None,\n",
    "        remove_silence=False,\n",
    "        file_wave=None,\n",
    "        file_spec=None,\n",
    "        seed=None,\n",
    "    ):\n",
    "        if seed is None:\n",
    "            seed = random.randint(0, sys.maxsize)\n",
    "        seed_everything(seed)\n",
    "        self.seed = seed\n",
    "\n",
    "        ref_file, ref_text = preprocess_ref_audio_text(ref_file, ref_text)\n",
    "\n",
    "        wav, sr, spec = infer_process(\n",
    "            ref_file,\n",
    "            ref_text,\n",
    "            gen_text,\n",
    "            self.ema_model,\n",
    "            self.vocoder,\n",
    "            self.mel_spec_type,\n",
    "            show_info=show_info,\n",
    "            progress=progress,\n",
    "            target_rms=target_rms,\n",
    "            cross_fade_duration=cross_fade_duration,\n",
    "            nfe_step=nfe_step,\n",
    "            cfg_strength=cfg_strength,\n",
    "            sway_sampling_coef=sway_sampling_coef,\n",
    "            speed=speed,\n",
    "            fix_duration=fix_duration,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        if file_wave is not None:\n",
    "            self.export_wav(wav, file_wave, remove_silence)\n",
    "\n",
    "        if file_spec is not None:\n",
    "            self.export_spectrogram(spec, file_spec)\n",
    "\n",
    "        return wav, sr, spec\n",
    "\n",
    "\n",
    "\n",
    "f5tts = F5TTS()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr, spec = f5tts.infer(\n",
    "        ref_file='D:\\Speech_program\\F5-TTS\\\\my(1).wav',\n",
    "        ref_text=\"说话的时候不能太快，也不能太慢。\",\n",
    "        gen_text=\"\"\"收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放\"\"\",\n",
    "        file_wave='D:\\Speech_program\\F5-TTS\\\\out1.wav',\n",
    "        seed=None,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
